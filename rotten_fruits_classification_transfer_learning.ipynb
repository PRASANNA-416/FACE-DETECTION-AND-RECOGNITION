{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rotten fruits classification transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMyB1d097hnCLFFuIuJbR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRASANNA-416/FACE-DETECTION-AND-RECOGNITION/blob/main/rotten_fruits_classification_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUKCcM33e_4l"
      },
      "source": [
        "Load ImageNet Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5HneT1L6hxP"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights = FIXME \n",
        "    input_shape = (224,224,3),\n",
        "    include_top = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcdTGLNIfqak"
      },
      "source": [
        "Freeze the base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBCEmFqx6h0K"
      },
      "source": [
        "base_model.trainable = FIXME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rec8ZuLNf4cM"
      },
      "source": [
        "Add Layers to Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCuCxHd6h3i"
      },
      "source": [
        "#create inputs with correct input shape\n",
        "inputs  = FIXME\n",
        "\n",
        "x = base_model(inputs , training = False)\n",
        " #add pooling or flatten layer\n",
        "\n",
        "x = FIXME\n",
        "\n",
        "#add final dense dense layer\n",
        "outputs = keras.layers.Dense(FIXME , activation = \"softmax\")(x)\n",
        "\n",
        "#combine the inputs and outputs to create the model\n",
        "model = keras.Model(FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X097-rLO6h7f"
      },
      "source": [
        "model.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvQ9C5uyhPUB"
      },
      "source": [
        "Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBI3QHPFhHF1"
      },
      "source": [
        "model.compile(loss = FIXME, metrics = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoNP8E45iA2n"
      },
      "source": [
        "Augment the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khW5RIo7hHI4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye3UYyrwimkQ"
      },
      "source": [
        "Load Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sweum8CdhHME"
      },
      "source": [
        "#load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory( \n",
        "                                       FIXME,\n",
        "                                       target_size = FIXME\n",
        "                                       color_mode = 'rgb'\n",
        "                                       class_mode = \"catgorical\")\n",
        ")\n",
        "#load and iterate validation dataset\n",
        "valid_it = datagent.flow_from_directory(\n",
        "                                        FIXME,\n",
        "                                        target_size = FIXME\n",
        "                                       color_mode = 'rgb'\n",
        "                                       class_mode = \"catgorical\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1RPIF4_kzLG"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvINWM3v6h_U"
      },
      "source": [
        "model.fit(FIXME,\n",
        "          validation_data = FIXME,\n",
        "          steps_per_epoch = train_it.samples/train_it.batch_size,\n",
        "          validation_steps = valid_it.samples/valid_it.batch_size,\n",
        "          epochs = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLVcDhoklwVS"
      },
      "source": [
        "unfreeze model for fine tuning \n",
        "OPTIONAL IF 92% ACCURACY IS REACHED \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy050l4ak1ne"
      },
      "source": [
        "# unfreeze the base model\n",
        "\n",
        "base_model.trainable = FIXME\n",
        "\n",
        "#compile the model with a low a learning rate\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.RMSprop(learing_rate = FIXME),\n",
        "              loss = FIXME , metrics = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ73EMNik1q7"
      },
      "source": [
        "model.fit(FIXME,\n",
        "          validation_data = FIXME,\n",
        "          steps_per_epoch = train_it.samples/train_it.batch_size,\n",
        "          validation_steps = valid_it.samples/valid_it.batch_size,\n",
        "          epochs = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mVuRLHnd6U"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCNT1tGXmy0V"
      },
      "source": [
        "model.evaluate(valid_it,steps = valid_it.samples/valid_it.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7d5cNURngZj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTt7ImnD6iGV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}